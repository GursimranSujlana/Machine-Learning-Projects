{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc49694a-9e82-4a39-95c8-d83cafb5102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a134b11-76fd-4c0b-9c1c-fdd8645db639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/5z71t9kj2yb0syg9m7v2fbnr0000gn/T/ipykernel_815/1964506953.py:3: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "#loading the raw data\n",
    "file_path = \"../data/Watershed_Water_Quality_-_Hydrology.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "667c5276-588f-46e7-b170-d5c9543a5f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Preview: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Id</th>\n",
       "      <th>Sample Site</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Sample Time</th>\n",
       "      <th>Analyte</th>\n",
       "      <th>Status</th>\n",
       "      <th>Final Result</th>\n",
       "      <th>Units</th>\n",
       "      <th>Stream Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-185028</td>\n",
       "      <td>S4</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.111110</td>\n",
       "      <td>C</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-186342</td>\n",
       "      <td>S6I</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>C</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-187744</td>\n",
       "      <td>S8</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.222220</td>\n",
       "      <td>C</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-185028</td>\n",
       "      <td>S4</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Scent Character</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C-186342</td>\n",
       "      <td>S6I</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Scent Character</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sample Id Sample Site Sample Date Sample Time          Analyte Status  \\\n",
       "0  C-185028          S4  1987-01-07         NaT      Temperature    NaN   \n",
       "1  C-186342         S6I  1987-01-07         NaT      Temperature    NaN   \n",
       "2  C-187744          S8  1987-01-07         NaT      Temperature    NaN   \n",
       "3  C-185028          S4  1987-01-07         NaT  Scent Character    NaN   \n",
       "4  C-186342         S6I  1987-01-07         NaT  Scent Character    NaN   \n",
       "\n",
       "   Final Result Units Stream Group  \n",
       "0      1.111110     C    Schoharie  \n",
       "1      0.555556     C    Schoharie  \n",
       "2      2.222220     C    Schoharie  \n",
       "3           NaN   NaN    Schoharie  \n",
       "4           NaN   NaN    Schoharie  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initial inspection\n",
    "print(\"Initial Data Preview: \")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02b02eb9-9682-4701-aaef-d446617c23ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Id</th>\n",
       "      <th>Sample Site</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Sample Time</th>\n",
       "      <th>Analyte</th>\n",
       "      <th>Status</th>\n",
       "      <th>Final Result</th>\n",
       "      <th>Units</th>\n",
       "      <th>Stream Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1664702</th>\n",
       "      <td>E-2301489-01</td>\n",
       "      <td>BOYDR</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>1900-01-01 09:52:00</td>\n",
       "      <td>Specific Conductance</td>\n",
       "      <td>Done</td>\n",
       "      <td>237.00</td>\n",
       "      <td>umhos/cm</td>\n",
       "      <td>West Branch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664703</th>\n",
       "      <td>E-2301489-03</td>\n",
       "      <td>CROSSRVVC</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>1900-01-01 08:40:00</td>\n",
       "      <td>Specific Conductance</td>\n",
       "      <td>Done</td>\n",
       "      <td>263.00</td>\n",
       "      <td>umhos/cm</td>\n",
       "      <td>Delaware Aqueduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664704</th>\n",
       "      <td>E-2301489-03</td>\n",
       "      <td>CROSSRVVC</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>1900-01-01 08:40:00</td>\n",
       "      <td>Turbidity</td>\n",
       "      <td>Done</td>\n",
       "      <td>1.60</td>\n",
       "      <td>NTU</td>\n",
       "      <td>Delaware Aqueduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664705</th>\n",
       "      <td>E-2301489-01</td>\n",
       "      <td>BOYDR</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>1900-01-01 09:52:00</td>\n",
       "      <td>Turbidity</td>\n",
       "      <td>Done</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NTU</td>\n",
       "      <td>West Branch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664706</th>\n",
       "      <td>E-2301489-02</td>\n",
       "      <td>CROFALLSVC</td>\n",
       "      <td>2023-04-25</td>\n",
       "      <td>1900-01-01 09:16:00</td>\n",
       "      <td>Turbidity</td>\n",
       "      <td>Done</td>\n",
       "      <td>0.99</td>\n",
       "      <td>NTU</td>\n",
       "      <td>Delaware Aqueduct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sample Id Sample Site Sample Date         Sample Time  \\\n",
       "1664702  E-2301489-01       BOYDR  2023-04-25 1900-01-01 09:52:00   \n",
       "1664703  E-2301489-03   CROSSRVVC  2023-04-25 1900-01-01 08:40:00   \n",
       "1664704  E-2301489-03   CROSSRVVC  2023-04-25 1900-01-01 08:40:00   \n",
       "1664705  E-2301489-01       BOYDR  2023-04-25 1900-01-01 09:52:00   \n",
       "1664706  E-2301489-02  CROFALLSVC  2023-04-25 1900-01-01 09:16:00   \n",
       "\n",
       "                      Analyte Status  Final Result     Units  \\\n",
       "1664702  Specific Conductance   Done        237.00  umhos/cm   \n",
       "1664703  Specific Conductance   Done        263.00  umhos/cm   \n",
       "1664704             Turbidity   Done          1.60       NTU   \n",
       "1664705             Turbidity   Done          0.96       NTU   \n",
       "1664706             Turbidity   Done          0.99       NTU   \n",
       "\n",
       "              Stream Group  \n",
       "1664702        West Branch  \n",
       "1664703  Delaware Aqueduct  \n",
       "1664704  Delaware Aqueduct  \n",
       "1664705        West Branch  \n",
       "1664706  Delaware Aqueduct  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75f62412-affc-4d8f-9fb9-0bc6792857bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sample Id', 'Sample Site', 'Sample Date', 'Sample Time', 'Analyte',\n",
       "       'Status', 'Final Result', 'Units', 'Stream Group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f1321f7-b748-4d69-be5a-3aff70e28d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't want the unwanted column in the begining\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5608b45f-dd32-4648-9f4f-4fa82b841692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1664707 entries, 0 to 1664706\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   Sample Id     1664707 non-null  object\n",
      " 1   Sample Site   1664707 non-null  object\n",
      " 2   Sample Date   1664707 non-null  object\n",
      " 3   Sample Time   1244822 non-null  object\n",
      " 4   Analyte       1664707 non-null  object\n",
      " 5   Status        298185 non-null   object\n",
      " 6   Final Result  1664676 non-null  object\n",
      " 7   Units         1528186 non-null  object\n",
      " 8   Stream Group  1661495 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 114.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "143484d4-0fbd-4182-b311-40463727e825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample Id               object\n",
       "Sample Site           category\n",
       "Sample Date     datetime64[ns]\n",
       "Sample Time     datetime64[ns]\n",
       "Analyte               category\n",
       "Status                category\n",
       "Final Result           float64\n",
       "Units                 category\n",
       "Stream Group          category\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as every column have Dtype as object, it would be great to convert the types accordingly\n",
    "\n",
    "#convert date and time\n",
    "df['Sample Date'] = pd.to_datetime(df['Sample Date'], errors = 'coerce')\n",
    "df['Sample Time'] = pd.to_datetime(df['Sample Time'], errors = 'coerce', format = '%H:%M:%S.%f')\n",
    "\n",
    "#converting numerical columns:\n",
    "df['Final Result'] = pd.to_numeric(df['Final Result'], errors = 'coerce')\n",
    "\n",
    "#converting categorical columns\n",
    "catergorical_cols = ['Sample Id', 'Sample Site', 'Analyte', 'Status', 'Units', 'Stream Group']\n",
    "df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "\n",
    "#display the updated data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21b205b3-ba79-452f-8c9c-5d5f6b783806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (1664707, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c021747b-8da2-44f5-b2f0-0ca5953635ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Sample Time</th>\n",
       "      <th>Final Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1664707</td>\n",
       "      <td>284857</td>\n",
       "      <td>1.420296e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2001-09-16 02:26:37.327577856</td>\n",
       "      <td>1900-01-01 11:01:51.187156480</td>\n",
       "      <td>1.047976e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1987-01-05 00:00:00</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>-1.638890e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1994-09-12 00:00:00</td>\n",
       "      <td>1900-01-01 10:05:00</td>\n",
       "      <td>1.250000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1999-11-15 00:00:00</td>\n",
       "      <td>1900-01-01 10:55:00</td>\n",
       "      <td>6.970000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2007-10-01 00:00:00</td>\n",
       "      <td>1900-01-01 11:50:00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>1900-01-01 23:56:00</td>\n",
       "      <td>1.470000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.752474e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Sample Date                    Sample Time  \\\n",
       "count                        1664707                         284857   \n",
       "mean   2001-09-16 02:26:37.327577856  1900-01-01 11:01:51.187156480   \n",
       "min              1987-01-05 00:00:00            1900-01-01 00:00:00   \n",
       "25%              1994-09-12 00:00:00            1900-01-01 10:05:00   \n",
       "50%              1999-11-15 00:00:00            1900-01-01 10:55:00   \n",
       "75%              2007-10-01 00:00:00            1900-01-01 11:50:00   \n",
       "max              2023-04-25 00:00:00            1900-01-01 23:56:00   \n",
       "std                              NaN                            NaN   \n",
       "\n",
       "       Final Result  \n",
       "count  1.420296e+06  \n",
       "mean   1.047976e+02  \n",
       "min   -1.638890e+01  \n",
       "25%    1.250000e+00  \n",
       "50%    6.970000e+00  \n",
       "75%    1.800000e+01  \n",
       "max    1.470000e+06  \n",
       "std    2.752474e+03  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688933d9-f010-4dd1-a83d-7a848eaaa9d3",
   "metadata": {},
   "source": [
    "📊 Interpretation of df.describe() Results\n",
    "\n",
    "1️⃣ Sample Date (Datetime)\n",
    "Total Samples with Dates: 1,664,707 (all non-null).\n",
    "Mean (Average Date): Sep 16, 2001 → Most samples are around this period.\n",
    "Oldest Sample: Jan 5, 1987 → Data collection started in 1987.\n",
    "Newest Sample: Apr 25, 2023 → Latest recorded sample.\n",
    "    \n",
    "Data Spread:\n",
    "25% of data is from before Sep 12, 1994.\n",
    "50% of data (median) is from before Nov 15, 1999.\n",
    "75% of data is from before Oct 1, 2007.\n",
    "    \n",
    "Key Insight:\n",
    "✅ Dataset covers a 36-year period (1987-2023), with more recent samples.\n",
    "    \n",
    "2️⃣ Sample Time (Datetime)\n",
    "Total Samples with Time Recorded: 284,857 (~17% of total data).\n",
    "Mean Time: 11:01 AM → Most samples were collected around this time.\n",
    "Earliest Time: 00:00:00 (Midnight).\n",
    "Latest Time: 23:56:00 (Near Midnight).\n",
    "    \n",
    "Data Spread:\n",
    "25% of samples were taken before 10:05 AM.\n",
    "50% (Median) were taken before 10:55 AM.\n",
    "75% of samples were taken before 11:50 AM.\n",
    "    \n",
    "Key Insight:\n",
    "✅ Most samples are collected in the morning, peaking before noon.\n",
    "✅ Many missing timestamps (~83% of data).\n",
    "    \n",
    "3️⃣ Final Result (Float - Measurement Values)\n",
    "Total Non-Null Values: 1,420,296 (some missing values).\n",
    "Mean (Average Value): 104.8 → Typical measurement reading.\n",
    "Minimum Value: -16.39 → Possible outlier (negative values in water quality?).\n",
    "Maximum Value: 1,470,000 → Very high, needs checking.\n",
    "    \n",
    "Data Spread:\n",
    "25% of values are below 1.25.\n",
    "50% (Median) of values are below 6.97.\n",
    "75% of values are below 18.0.\n",
    "Standard Deviation (Std): 2,752.47 → Extremely high variation.\n",
    "    \n",
    "Key Insight:\n",
    "✅ Possible data quality issues due to extreme outliers.\n",
    "✅ Most readings are below 20, but max = 1.47M suggests anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53f5d175-e6b2-4787-b6ed-f2fcbc60a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows found: 16\n",
      "Displaying duplicate rows:\n",
      "            Sample Id Sample Site Sample Date         Sample Time  \\\n",
      "1580221  E-1901638-01         BG9  2019-04-17 1900-01-01 11:44:00   \n",
      "1580239  E-1901638-01         BG9  2019-04-17 1900-01-01 11:44:00   \n",
      "1580367  E-1901638-02          E9  2019-04-17 1900-01-01 10:32:00   \n",
      "1580392  E-1901638-02          E9  2019-04-17 1900-01-01 10:32:00   \n",
      "1580251  E-1901638-03         E10  2019-04-17 1900-01-01 10:50:00   \n",
      "1580269  E-1901638-03         E10  2019-04-17 1900-01-01 10:50:00   \n",
      "1580281  E-1901638-04         E11  2019-04-17 1900-01-01 11:22:00   \n",
      "1580291  E-1901638-04         E11  2019-04-17 1900-01-01 11:22:00   \n",
      "1580342  E-1901638-05        MB-1  2019-04-17 1900-01-01 13:18:00   \n",
      "1580371  E-1901638-05        MB-1  2019-04-17 1900-01-01 13:18:00   \n",
      "1580174  E-1901638-06         N12  2019-04-17 1900-01-01 12:22:00   \n",
      "1580324  E-1901638-06         N12  2019-04-17 1900-01-01 12:22:00   \n",
      "1580199  E-1901638-07        N5-1  2019-04-17 1900-01-01 12:55:00   \n",
      "1580209  E-1901638-07        N5-1  2019-04-17 1900-01-01 12:55:00   \n",
      "1580204  E-1901638-08        WHIP  2019-04-17 1900-01-01 12:05:00   \n",
      "1580312  E-1901638-08        WHIP  2019-04-17 1900-01-01 12:05:00   \n",
      "\n",
      "              Analyte Status  Final Result Units Stream Group  \n",
      "1580221  Indium (115)   Done          98.0     %      Kensico  \n",
      "1580239  Indium (115)   Done          98.0     %      Kensico  \n",
      "1580367  Indium (115)   Done          99.0     %      Kensico  \n",
      "1580392  Indium (115)   Done          99.0     %      Kensico  \n",
      "1580251  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580269  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580281  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580291  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580342  Indium (115)   Done          98.0     %      Kensico  \n",
      "1580371  Indium (115)   Done          98.0     %      Kensico  \n",
      "1580174  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580324  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580199  Indium (115)   Done          96.0     %      Kensico  \n",
      "1580209  Indium (115)   Done          96.0     %      Kensico  \n",
      "1580204  Indium (115)   Done          98.0   NaN      Kensico  \n",
      "1580312  Indium (115)   Done          98.0   NaN      Kensico  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to remove all duplicate rows? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed. New Shape: (1664699, 9)\n"
     ]
    }
   ],
   "source": [
    "# seeing duplicate rows and handling duplicates\n",
    "duplicate_rows = df[df.duplicated(keep=False)]\n",
    "print(f\"Duplicate rows found: {len(duplicate_rows)}\")\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"Displaying duplicate rows:\")\n",
    "    print(duplicate_rows.sort_values(by=['Sample Id', 'Sample Date', 'Sample Time']))\n",
    "    user_decision = input(\"Do you want to remove all duplicate rows? (yes/no): \")\n",
    "    if user_decision.lower() == 'yes':\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(f\"Duplicates removed. New Shape: {df.shape}\")\n",
    "    else:\n",
    "        print(\"No duplicates were removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "009caed3-e6ef-41d6-a765-353d4b9cd050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Id: 117078 unique values\n",
      "Sample Site: 423 unique values\n",
      "Sample Date: 8351 unique values\n",
      "Sample Time: 807 unique values\n",
      "Analyte: 348 unique values\n",
      "Status: 5 unique values\n",
      "Final Result: 13857 unique values\n",
      "Units: 28 unique values\n",
      "Stream Group: 16 unique values\n"
     ]
    }
   ],
   "source": [
    "# number of unique values in each columns\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93efcd43-7e02-470f-91c8-54d783b07eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Time     82.888859\n",
      "Status          82.088233\n",
      "Final Result    14.681994\n",
      "Units            8.200882\n",
      "Stream Group     0.192948\n",
      "Sample Id        0.000000\n",
      "Analyte          0.000000\n",
      "Sample Site      0.000000\n",
      "Sample Date      0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#checking missing values percentage:\n",
    "missing_percentage = (df.isnull().sum() / len(df))*100\n",
    "print(missing_percentage.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b2877-9be6-4bf2-a3fc-65c545b530a0",
   "metadata": {},
   "source": [
    " Interpretation of Missing Data Percentage\n",
    " \n",
    "Sample Time → 82.89% missing\n",
    "🔴 Critical issue: Only ~17% of samples have a recorded time.\n",
    "🔹 Suggestion: Drop this column if time is not important, or analyze missing patterns.\n",
    "\n",
    "Status → 82.09% missing\n",
    "🔴 Severely incomplete: Only ~18% of records have a status.\n",
    "🔹 Suggestion: Check if missing values correlate with a certain type of data.\n",
    "\n",
    "Final Result → 14.68% missing\n",
    "🟡 Moderate issue: ~15% of sample measurements are missing.\n",
    "🔹 Suggestion: Consider imputation (e.g., median value) or drop missing rows if necessary.\n",
    "\n",
    "Units → 8.20% missing\n",
    "🟡 Small issue: Units are missing in ~8% of cases.\n",
    "🔹 Suggestion: Check if certain analytes are more affected.\n",
    "\n",
    "Stream Group → 0.19% missing\n",
    "✅ Minor issue: Less than 1% missing → Not a major concern.\n",
    "\n",
    "Sample Id, Analyte, Sample Site, Sample Date → 0% missing\n",
    "✅ Perfect! These columns have complete data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a64de892-6fea-4490-930f-ac57d2b01aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['Sample Time', 'Status']\n"
     ]
    }
   ],
   "source": [
    "#dropping columns with excessive missing values\n",
    "drop_columns = ['Sample Time', 'Status']\n",
    "df.drop(columns=drop_columns, inplace=True)\n",
    "print(f\"Dropped columns: {drop_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "624578b3-3028-4a42-aec4-345a89321ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values without explicit assignment of inplace=True as it might support some panda versions in the future\n",
    "df = df.assign(\n",
    "    Units = df['Units'].fillna(df['Units'].mode()[0]),\n",
    "    Stream_Group = df['Stream Group'].fillna(df['Stream Group'].mode()[0]),    \n",
    "    Final_Result = df['Final Result'].fillna(df['Final Result'].median())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8801c8a9-5501-4db5-83e6-20b91f9a5fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values in 'Final Result':\n",
      "            Sample Id Sample Site Sample Date      Analyte  Final Result  \\\n",
      "217           E-96871   MIDDLEBRR  1987-01-05  Temperature      -1.11111   \n",
      "371           E-95643     EASTBRR  1987-01-05  Temperature      -2.22222   \n",
      "499           D-69955         RD1  1987-01-06  Temperature      -1.00000   \n",
      "623           D-70457         RD4  1987-01-06  Temperature      -2.00000   \n",
      "835           E-98396     WESTBRR  1987-01-06  Temperature      -2.22222   \n",
      "...               ...         ...         ...          ...           ...   \n",
      "1545405  K-1800859-04       STHHG  2018-03-12  Temperature      -0.10000   \n",
      "1548055  K-1801184-02        SSHG  2018-04-09  Temperature      -0.20000   \n",
      "1548059  K-1801184-03        SSMA  2018-04-09  Temperature      -0.20000   \n",
      "1602967  G-2000341-11         NCG  2020-01-27     fDOM RFU      -0.10000   \n",
      "1607029  G-2000999-09         NCG  2020-03-16     fDOM RFU      -0.10000   \n",
      "\n",
      "        Units   Stream Group   Stream_Group  Final_Result  \n",
      "217         C  EOH Hydrology  EOH Hydrology      -1.11111  \n",
      "371         C  EOH Hydrology  EOH Hydrology      -2.22222  \n",
      "499         C        Rondout        Rondout      -1.00000  \n",
      "623         C        Rondout        Rondout      -2.00000  \n",
      "835         C    West Branch    West Branch      -2.22222  \n",
      "...       ...            ...            ...           ...  \n",
      "1545405     C      Schoharie      Schoharie      -0.10000  \n",
      "1548055     C      Schoharie      Schoharie      -0.20000  \n",
      "1548059     C      Schoharie      Schoharie      -0.20000  \n",
      "1602967   RFU      Neversink      Neversink      -0.10000  \n",
      "1607029   RFU      Neversink      Neversink      -0.10000  \n",
      "\n",
      "[2480 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#checking for negative or extreme values:\n",
    "print(\"Negative values in 'Final Result':\")\n",
    "print(df[df['Final Result'] < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc918695-9361-49b5-b6d3-7d114d480dc8",
   "metadata": {},
   "source": [
    "Found 2,480 rows with negative values in Final Result, which likely indicates errors, missing data representations, or incorrect measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8cc434d-74da-492a-a2a9-25786b0bfad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Sample Id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#removing unncessary columns\u001b[39;00m\n\u001b[1;32m      2\u001b[0m drop_unnecessary \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample Id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_unnecessary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDropped unnecessary columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrop_unnecessary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Sample Id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#removing unncessary columns\n",
    "drop_unnecessary = ['Sample Id']\n",
    "df.drop(columns=drop_unnecessary, inplace=True)\n",
    "print(f\"Dropped unnecessary columns: {drop_unnecessary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4e3b7124-0f06-4495-abf0-f67d72bdeefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed. Cleaned dataset saved to ../data/cleaned_water_quality.csv\n",
      "Final Dataset shape: (1664699, 8)\n"
     ]
    }
   ],
   "source": [
    "# saving the cleaned file\n",
    "cleaned_file_path = \"../data/cleaned_water_quality.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"Data cleaning completed. Cleaned dataset saved to {cleaned_file_path}\")\n",
    "print(f\"Final Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fffe3f-9241-4e93-8307-323206cabde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece7e60-8125-4536-a524-0613766d1599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
