{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc49694a-9e82-4a39-95c8-d83cafb5102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a134b11-76fd-4c0b-9c1c-fdd8645db639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2t/5z71t9kj2yb0syg9m7v2fbnr0000gn/T/ipykernel_2673/1964506953.py:3: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "#loading the raw data\n",
    "file_path = \"../data/Watershed_Water_Quality_-_Hydrology.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667c5276-588f-46e7-b170-d5c9543a5f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Preview: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Id</th>\n",
       "      <th>Sample Site</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Sample Time</th>\n",
       "      <th>Analyte</th>\n",
       "      <th>Status</th>\n",
       "      <th>Final Result</th>\n",
       "      <th>Units</th>\n",
       "      <th>Stream Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C-185028</td>\n",
       "      <td>S4</td>\n",
       "      <td>01/07/1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.11111</td>\n",
       "      <td>C</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C-186342</td>\n",
       "      <td>S6I</td>\n",
       "      <td>01/07/1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>C</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C-187744</td>\n",
       "      <td>S8</td>\n",
       "      <td>01/07/1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.22222</td>\n",
       "      <td>C</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C-185028</td>\n",
       "      <td>S4</td>\n",
       "      <td>01/07/1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scent Character</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C-186342</td>\n",
       "      <td>S6I</td>\n",
       "      <td>01/07/1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scent Character</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sample Id Sample Site Sample Date Sample Time          Analyte Status  \\\n",
       "0  C-185028          S4  01/07/1987         NaN      Temperature    NaN   \n",
       "1  C-186342         S6I  01/07/1987         NaN      Temperature    NaN   \n",
       "2  C-187744          S8  01/07/1987         NaN      Temperature    NaN   \n",
       "3  C-185028          S4  01/07/1987         NaN  Scent Character    NaN   \n",
       "4  C-186342         S6I  01/07/1987         NaN  Scent Character    NaN   \n",
       "\n",
       "  Final Result Units Stream Group  \n",
       "0      1.11111     C    Schoharie  \n",
       "1     0.555556     C    Schoharie  \n",
       "2      2.22222     C    Schoharie  \n",
       "3           1V   NaN    Schoharie  \n",
       "4           1V   NaN    Schoharie  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initial inspection\n",
    "print(\"Initial Data Preview: \")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b02eb9-9682-4701-aaef-d446617c23ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Id</th>\n",
       "      <th>Sample Site</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Sample Time</th>\n",
       "      <th>Analyte</th>\n",
       "      <th>Status</th>\n",
       "      <th>Final Result</th>\n",
       "      <th>Units</th>\n",
       "      <th>Stream Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1664702</th>\n",
       "      <td>E-2301489-01</td>\n",
       "      <td>BOYDR</td>\n",
       "      <td>04/25/2023</td>\n",
       "      <td>09:52:00.000</td>\n",
       "      <td>Specific Conductance</td>\n",
       "      <td>Done</td>\n",
       "      <td>237</td>\n",
       "      <td>umhos/cm</td>\n",
       "      <td>West Branch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664703</th>\n",
       "      <td>E-2301489-03</td>\n",
       "      <td>CROSSRVVC</td>\n",
       "      <td>04/25/2023</td>\n",
       "      <td>08:40:00.000</td>\n",
       "      <td>Specific Conductance</td>\n",
       "      <td>Done</td>\n",
       "      <td>263</td>\n",
       "      <td>umhos/cm</td>\n",
       "      <td>Delaware Aqueduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664704</th>\n",
       "      <td>E-2301489-03</td>\n",
       "      <td>CROSSRVVC</td>\n",
       "      <td>04/25/2023</td>\n",
       "      <td>08:40:00.000</td>\n",
       "      <td>Turbidity</td>\n",
       "      <td>Done</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NTU</td>\n",
       "      <td>Delaware Aqueduct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664705</th>\n",
       "      <td>E-2301489-01</td>\n",
       "      <td>BOYDR</td>\n",
       "      <td>04/25/2023</td>\n",
       "      <td>09:52:00.000</td>\n",
       "      <td>Turbidity</td>\n",
       "      <td>Done</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NTU</td>\n",
       "      <td>West Branch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664706</th>\n",
       "      <td>E-2301489-02</td>\n",
       "      <td>CROFALLSVC</td>\n",
       "      <td>04/25/2023</td>\n",
       "      <td>09:16:00.000</td>\n",
       "      <td>Turbidity</td>\n",
       "      <td>Done</td>\n",
       "      <td>0.99</td>\n",
       "      <td>NTU</td>\n",
       "      <td>Delaware Aqueduct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sample Id Sample Site Sample Date   Sample Time  \\\n",
       "1664702  E-2301489-01       BOYDR  04/25/2023  09:52:00.000   \n",
       "1664703  E-2301489-03   CROSSRVVC  04/25/2023  08:40:00.000   \n",
       "1664704  E-2301489-03   CROSSRVVC  04/25/2023  08:40:00.000   \n",
       "1664705  E-2301489-01       BOYDR  04/25/2023  09:52:00.000   \n",
       "1664706  E-2301489-02  CROFALLSVC  04/25/2023  09:16:00.000   \n",
       "\n",
       "                      Analyte Status Final Result     Units       Stream Group  \n",
       "1664702  Specific Conductance   Done          237  umhos/cm        West Branch  \n",
       "1664703  Specific Conductance   Done          263  umhos/cm  Delaware Aqueduct  \n",
       "1664704             Turbidity   Done          1.6       NTU  Delaware Aqueduct  \n",
       "1664705             Turbidity   Done         0.96       NTU        West Branch  \n",
       "1664706             Turbidity   Done         0.99       NTU  Delaware Aqueduct  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f62412-affc-4d8f-9fb9-0bc6792857bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sample Id', 'Sample Site', 'Sample Date', 'Sample Time', 'Analyte',\n",
       "       'Status', 'Final Result', 'Units', 'Stream Group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5608b45f-dd32-4648-9f4f-4fa82b841692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1664707 entries, 0 to 1664706\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   Sample Id     1664707 non-null  object\n",
      " 1   Sample Site   1664707 non-null  object\n",
      " 2   Sample Date   1664707 non-null  object\n",
      " 3   Sample Time   1244822 non-null  object\n",
      " 4   Analyte       1664707 non-null  object\n",
      " 5   Status        298185 non-null   object\n",
      " 6   Final Result  1664676 non-null  object\n",
      " 7   Units         1528186 non-null  object\n",
      " 8   Stream Group  1661495 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 114.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143484d4-0fbd-4182-b311-40463727e825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sample Id             category\n",
       "Sample Site           category\n",
       "Sample Date     datetime64[ns]\n",
       "Sample Time     datetime64[ns]\n",
       "Analyte               category\n",
       "Status                category\n",
       "Final Result           float64\n",
       "Units                 category\n",
       "Stream Group          category\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as every column have Dtype as object, it would be great to convert the types accordingly\n",
    "\n",
    "#convert date and time\n",
    "df['Sample Date'] = pd.to_datetime(df['Sample Date'], errors = 'coerce')\n",
    "df['Sample Time'] = pd.to_datetime(df['Sample Time'], errors = 'coerce', format = '%H:%M:%S.%f')\n",
    "\n",
    "#converting numerical columns:\n",
    "df['Final Result'] = pd.to_numeric(df['Final Result'], errors = 'coerce')\n",
    "\n",
    "#converting categorical columns\n",
    "catergorical_cols = ['Sample Id', 'Sample Site', 'Analyte', 'Status', 'Units', 'Stream Group']\n",
    "df[catergorical_cols] = df[catergorical_cols].astype('category')\n",
    "\n",
    "#display the updated data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21b205b3-ba79-452f-8c9c-5d5f6b783806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (1664707, 9)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c021747b-8da2-44f5-b2f0-0ca5953635ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Sample Time</th>\n",
       "      <th>Final Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1664707</td>\n",
       "      <td>284857</td>\n",
       "      <td>1.420296e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2001-09-16 02:26:37.327577856</td>\n",
       "      <td>1900-01-01 11:01:51.187156480</td>\n",
       "      <td>1.047976e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1987-01-05 00:00:00</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>-1.638890e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1994-09-12 00:00:00</td>\n",
       "      <td>1900-01-01 10:05:00</td>\n",
       "      <td>1.250000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1999-11-15 00:00:00</td>\n",
       "      <td>1900-01-01 10:55:00</td>\n",
       "      <td>6.970000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2007-10-01 00:00:00</td>\n",
       "      <td>1900-01-01 11:50:00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-04-25 00:00:00</td>\n",
       "      <td>1900-01-01 23:56:00</td>\n",
       "      <td>1.470000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.752474e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Sample Date                    Sample Time  \\\n",
       "count                        1664707                         284857   \n",
       "mean   2001-09-16 02:26:37.327577856  1900-01-01 11:01:51.187156480   \n",
       "min              1987-01-05 00:00:00            1900-01-01 00:00:00   \n",
       "25%              1994-09-12 00:00:00            1900-01-01 10:05:00   \n",
       "50%              1999-11-15 00:00:00            1900-01-01 10:55:00   \n",
       "75%              2007-10-01 00:00:00            1900-01-01 11:50:00   \n",
       "max              2023-04-25 00:00:00            1900-01-01 23:56:00   \n",
       "std                              NaN                            NaN   \n",
       "\n",
       "       Final Result  \n",
       "count  1.420296e+06  \n",
       "mean   1.047976e+02  \n",
       "min   -1.638890e+01  \n",
       "25%    1.250000e+00  \n",
       "50%    6.970000e+00  \n",
       "75%    1.800000e+01  \n",
       "max    1.470000e+06  \n",
       "std    2.752474e+03  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688933d9-f010-4dd1-a83d-7a848eaaa9d3",
   "metadata": {},
   "source": [
    "📊 Interpretation of df.describe() Results\n",
    "\n",
    "1️⃣ Sample Date (Datetime)\n",
    "Total Samples with Dates: 1,664,707 (all non-null).\n",
    "Mean (Average Date): Sep 16, 2001 → Most samples are around this period.\n",
    "Oldest Sample: Jan 5, 1987 → Data collection started in 1987.\n",
    "Newest Sample: Apr 25, 2023 → Latest recorded sample.\n",
    "    \n",
    "Data Spread:\n",
    "25% of data is from before Sep 12, 1994.\n",
    "50% of data (median) is from before Nov 15, 1999.\n",
    "75% of data is from before Oct 1, 2007.\n",
    "    \n",
    "Key Insight:\n",
    "✅ Dataset covers a 36-year period (1987-2023), with more recent samples.\n",
    "    \n",
    "2️⃣ Sample Time (Datetime)\n",
    "Total Samples with Time Recorded: 284,857 (~17% of total data).\n",
    "Mean Time: 11:01 AM → Most samples were collected around this time.\n",
    "Earliest Time: 00:00:00 (Midnight).\n",
    "Latest Time: 23:56:00 (Near Midnight).\n",
    "    \n",
    "Data Spread:\n",
    "25% of samples were taken before 10:05 AM.\n",
    "50% (Median) were taken before 10:55 AM.\n",
    "75% of samples were taken before 11:50 AM.\n",
    "    \n",
    "Key Insight:\n",
    "✅ Most samples are collected in the morning, peaking before noon.\n",
    "✅ Many missing timestamps (~83% of data).\n",
    "    \n",
    "3️⃣ Final Result (Float - Measurement Values)\n",
    "Total Non-Null Values: 1,420,296 (some missing values).\n",
    "Mean (Average Value): 104.8 → Typical measurement reading.\n",
    "Minimum Value: -16.39 → Possible outlier (negative values in water quality?).\n",
    "Maximum Value: 1,470,000 → Very high, needs checking.\n",
    "    \n",
    "Data Spread:\n",
    "25% of values are below 1.25.\n",
    "50% (Median) of values are below 6.97.\n",
    "75% of values are below 18.0.\n",
    "Standard Deviation (Std): 2,752.47 → Extremely high variation.\n",
    "    \n",
    "Key Insight:\n",
    "✅ Possible data quality issues due to extreme outliers.\n",
    "✅ Most readings are below 20, but max = 1.47M suggests anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f5d175-e6b2-4787-b6ed-f2fcbc60a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows found: 16\n",
      "Displaying duplicate rows:\n",
      "            Sample Id Sample Site Sample Date         Sample Time  \\\n",
      "1580221  E-1901638-01         BG9  2019-04-17 1900-01-01 11:44:00   \n",
      "1580239  E-1901638-01         BG9  2019-04-17 1900-01-01 11:44:00   \n",
      "1580367  E-1901638-02          E9  2019-04-17 1900-01-01 10:32:00   \n",
      "1580392  E-1901638-02          E9  2019-04-17 1900-01-01 10:32:00   \n",
      "1580251  E-1901638-03         E10  2019-04-17 1900-01-01 10:50:00   \n",
      "1580269  E-1901638-03         E10  2019-04-17 1900-01-01 10:50:00   \n",
      "1580281  E-1901638-04         E11  2019-04-17 1900-01-01 11:22:00   \n",
      "1580291  E-1901638-04         E11  2019-04-17 1900-01-01 11:22:00   \n",
      "1580342  E-1901638-05        MB-1  2019-04-17 1900-01-01 13:18:00   \n",
      "1580371  E-1901638-05        MB-1  2019-04-17 1900-01-01 13:18:00   \n",
      "1580174  E-1901638-06         N12  2019-04-17 1900-01-01 12:22:00   \n",
      "1580324  E-1901638-06         N12  2019-04-17 1900-01-01 12:22:00   \n",
      "1580199  E-1901638-07        N5-1  2019-04-17 1900-01-01 12:55:00   \n",
      "1580209  E-1901638-07        N5-1  2019-04-17 1900-01-01 12:55:00   \n",
      "1580204  E-1901638-08        WHIP  2019-04-17 1900-01-01 12:05:00   \n",
      "1580312  E-1901638-08        WHIP  2019-04-17 1900-01-01 12:05:00   \n",
      "\n",
      "              Analyte Status  Final Result Units Stream Group  \n",
      "1580221  Indium (115)   Done          98.0     %      Kensico  \n",
      "1580239  Indium (115)   Done          98.0     %      Kensico  \n",
      "1580367  Indium (115)   Done          99.0     %      Kensico  \n",
      "1580392  Indium (115)   Done          99.0     %      Kensico  \n",
      "1580251  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580269  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580281  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580291  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580342  Indium (115)   Done          98.0     %      Kensico  \n",
      "1580371  Indium (115)   Done          98.0     %      Kensico  \n",
      "1580174  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580324  Indium (115)   Done          97.0     %      Kensico  \n",
      "1580199  Indium (115)   Done          96.0     %      Kensico  \n",
      "1580209  Indium (115)   Done          96.0     %      Kensico  \n",
      "1580204  Indium (115)   Done          98.0   NaN      Kensico  \n",
      "1580312  Indium (115)   Done          98.0   NaN      Kensico  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to remove all duplicate rows? (yes/no):  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed. New Shape: (1664699, 9)\n"
     ]
    }
   ],
   "source": [
    "# seeing duplicate rows and handling duplicates\n",
    "duplicate_rows = df[df.duplicated(keep=False)]\n",
    "print(f\"Duplicate rows found: {len(duplicate_rows)}\")\n",
    "if not duplicate_rows.empty:\n",
    "    print(\"Displaying duplicate rows:\")\n",
    "    print(duplicate_rows.sort_values(by=['Sample Id', 'Sample Date', 'Sample Time']))\n",
    "    user_decision = input(\"Do you want to remove all duplicate rows? (yes/no): \")\n",
    "    if user_decision.lower() == 'yes':\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(f\"Duplicates removed. New Shape: {df.shape}\")\n",
    "    else:\n",
    "        print(\"No duplicates were removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "009caed3-e6ef-41d6-a765-353d4b9cd050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Id: 117078 unique values\n",
      "Sample Site: 423 unique values\n",
      "Sample Date: 8351 unique values\n",
      "Sample Time: 807 unique values\n",
      "Analyte: 348 unique values\n",
      "Status: 5 unique values\n",
      "Final Result: 13857 unique values\n",
      "Units: 28 unique values\n",
      "Stream Group: 16 unique values\n"
     ]
    }
   ],
   "source": [
    "# number of unique values in each columns\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93efcd43-7e02-470f-91c8-54d783b07eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Time     82.888859\n",
      "Status          82.088233\n",
      "Final Result    14.681994\n",
      "Units            8.200882\n",
      "Stream Group     0.192948\n",
      "Sample Id        0.000000\n",
      "Analyte          0.000000\n",
      "Sample Site      0.000000\n",
      "Sample Date      0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#checking missing values percentage:\n",
    "missing_percentage = (df.isnull().sum() / len(df))*100\n",
    "print(missing_percentage.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b2877-9be6-4bf2-a3fc-65c545b530a0",
   "metadata": {},
   "source": [
    " Interpretation of Missing Data Percentage\n",
    " \n",
    "Sample Time → 82.89% missing\n",
    "🔴 Critical issue: Only ~17% of samples have a recorded time.\n",
    "🔹 Suggestion: Drop this column if time is not important, or analyze missing patterns.\n",
    "\n",
    "Status → 82.09% missing\n",
    "🔴 Severely incomplete: Only ~18% of records have a status.\n",
    "🔹 Suggestion: Check if missing values correlate with a certain type of data.\n",
    "\n",
    "Final Result → 14.68% missing\n",
    "🟡 Moderate issue: ~15% of sample measurements are missing.\n",
    "🔹 Suggestion: Consider imputation (e.g., median value) or drop missing rows if necessary.\n",
    "\n",
    "Units → 8.20% missing\n",
    "🟡 Small issue: Units are missing in ~8% of cases.\n",
    "🔹 Suggestion: Check if certain analytes are more affected.\n",
    "\n",
    "Stream Group → 0.19% missing\n",
    "✅ Minor issue: Less than 1% missing → Not a major concern.\n",
    "\n",
    "Sample Id, Analyte, Sample Site, Sample Date → 0% missing\n",
    "✅ Perfect! These columns have complete data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a64de892-6fea-4490-930f-ac57d2b01aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['Sample Time', 'Status']\n"
     ]
    }
   ],
   "source": [
    "#dropping columns with excessive missing values\n",
    "drop_columns = ['Sample Time', 'Status']\n",
    "df.drop(columns=drop_columns, inplace=True)\n",
    "print(f\"Dropped columns: {drop_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "624578b3-3028-4a42-aec4-345a89321ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing values without explicit assignment of inplace=True as it might support some panda versions in the future\n",
    "df['Units'] = df['Units'].fillna(df['Units'].mode()[0])\n",
    "df['Stream Group'] = df['Stream Group'].fillna(df['Stream Group'].mode()[0])\n",
    "df['Final Result'] = df['Final Result'].fillna(df['Final Result'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8801c8a9-5501-4db5-83e6-20b91f9a5fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values in 'Final Result':\n",
      "            Sample Id Sample Site Sample Date      Analyte  Final Result  \\\n",
      "217           E-96871   MIDDLEBRR  1987-01-05  Temperature      -1.11111   \n",
      "371           E-95643     EASTBRR  1987-01-05  Temperature      -2.22222   \n",
      "499           D-69955         RD1  1987-01-06  Temperature      -1.00000   \n",
      "623           D-70457         RD4  1987-01-06  Temperature      -2.00000   \n",
      "835           E-98396     WESTBRR  1987-01-06  Temperature      -2.22222   \n",
      "...               ...         ...         ...          ...           ...   \n",
      "1545405  K-1800859-04       STHHG  2018-03-12  Temperature      -0.10000   \n",
      "1548055  K-1801184-02        SSHG  2018-04-09  Temperature      -0.20000   \n",
      "1548059  K-1801184-03        SSMA  2018-04-09  Temperature      -0.20000   \n",
      "1602967  G-2000341-11         NCG  2020-01-27     fDOM RFU      -0.10000   \n",
      "1607029  G-2000999-09         NCG  2020-03-16     fDOM RFU      -0.10000   \n",
      "\n",
      "        Units   Stream Group  \n",
      "217         C  EOH Hydrology  \n",
      "371         C  EOH Hydrology  \n",
      "499         C        Rondout  \n",
      "623         C        Rondout  \n",
      "835         C    West Branch  \n",
      "...       ...            ...  \n",
      "1545405     C      Schoharie  \n",
      "1548055     C      Schoharie  \n",
      "1548059     C      Schoharie  \n",
      "1602967   RFU      Neversink  \n",
      "1607029   RFU      Neversink  \n",
      "\n",
      "[2480 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#checking for negative or extreme values:\n",
    "print(\"Negative values in 'Final Result':\")\n",
    "print(df[df['Final Result'] < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc918695-9361-49b5-b6d3-7d114d480dc8",
   "metadata": {},
   "source": [
    "Found 2,480 rows with negative values in Final Result, which likely indicates errors, missing data representations, or incorrect measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8cc434d-74da-492a-a2a9-25786b0bfad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped unnecessary columns: ['Sample Id']\n"
     ]
    }
   ],
   "source": [
    "#removing unncessary columns\n",
    "drop_unnecessary = ['Sample Id']\n",
    "df.drop(columns=drop_unnecessary, inplace=True)\n",
    "print(f\"Dropped unnecessary columns: {drop_unnecessary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31fe441d-b627-4230-a82a-b1a1fe16180e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Site</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Analyte</th>\n",
       "      <th>Final Result</th>\n",
       "      <th>Units</th>\n",
       "      <th>Stream Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S4</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>1.111110</td>\n",
       "      <td>C</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S6I</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>C</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S8</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>2.222220</td>\n",
       "      <td>C</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S4</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>Scent Character</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>mg/L</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S6I</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>Scent Character</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>mg/L</td>\n",
       "      <td>Schoharie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sample Site Sample Date          Analyte  Final Result Units Stream Group\n",
       "0          S4  1987-01-07      Temperature      1.111110     C    Schoharie\n",
       "1         S6I  1987-01-07      Temperature      0.555556     C    Schoharie\n",
       "2          S8  1987-01-07      Temperature      2.222220     C    Schoharie\n",
       "3          S4  1987-01-07  Scent Character      6.970000  mg/L    Schoharie\n",
       "4         S6I  1987-01-07  Scent Character      6.970000  mg/L    Schoharie"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e3b7124-0f06-4495-abf0-f67d72bdeefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed. Cleaned dataset saved to ../data/cleaned_water_quality.csv\n",
      "Final Dataset shape: (1664699, 6)\n"
     ]
    }
   ],
   "source": [
    "# saving the cleaned file\n",
    "cleaned_file_path = \"../data/cleaned_water_quality.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"Data cleaning completed. Cleaned dataset saved to {cleaned_file_path}\")\n",
    "print(f\"Final Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89fffe3f-9241-4e93-8307-323206cabde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique sample sites: 423\n"
     ]
    }
   ],
   "source": [
    "#unique sample sites\n",
    "print(\"unique sample sites:\", df['Sample Site'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cece7e60-8125-4536-a524-0613766d1599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Analytes: 348\n"
     ]
    }
   ],
   "source": [
    "#unique analytes\n",
    "print(\"Unique Analytes:\", df['Analyte'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20d1defd-2134-43b0-8728-13df79c47bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique Stream Groups: 16\n"
     ]
    }
   ],
   "source": [
    "#unique Stream Groups\n",
    "print(\"unique Stream Groups:\", df[\"Stream Group\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79bc5503-f3c8-4a7c-80be-09b9ddd68f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Units: ['C', 'mg/L', 'CU', 'CFU/100mL', 'NTU', ..., 'QSU', 'pCi/L', 'ng/L', '%', 'Foci Count']\n",
      "Length: 28\n",
      "Categories (28, object): ['%', '/100ml', 'ASU/mL', 'C', ..., 'nm', 'pCi/L', 'umhos/cm', 'µg/L']\n"
     ]
    }
   ],
   "source": [
    "#unique units\n",
    "print(\"Unique Units:\", df[\"Units\"].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
